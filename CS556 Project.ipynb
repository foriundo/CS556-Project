{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07cd4d83",
   "metadata": {},
   "source": [
    "<h1>CS 556 Project</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff47e12",
   "metadata": {},
   "source": [
    "<h2>1. Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d809142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "plt.style.use(['ggplot'])\n",
    "%matplotlib inline\n",
    "#test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708c426",
   "metadata": {},
   "source": [
    "<h2>2. Reading CSV </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c106c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('College_Admissions.csv')\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b03b11",
   "metadata": {},
   "source": [
    "<h2>3. Data and Distribution</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a184db",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['GRE Score','CGPA','University Rating']\n",
    "colors = ['purple', 'green', 'brown']\n",
    "\n",
    "for dataset,c in zip(datasets,colors):\n",
    "    plt.hist(df[dataset], bins=30, edgecolor = 'black', color= c)\n",
    "    plt.title(dataset)\n",
    "    plt.xlabel(f'{dataset} Distribution')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "print(df[datasets].describe())\n",
    "\n",
    "#Calculating correlation matrix\n",
    "print(df[datasets + ['Chance of Admit ']].corr())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c22156",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(df['GRE Score'], df['Chance of Admit '], alpha=0.5)\n",
    "plt.title('GRE Score vs. Chance of Admit')\n",
    "plt.xlabel('GRE Score')\n",
    "plt.ylabel('Chance of Admit')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(df['CGPA'], df['Chance of Admit '], alpha=0.5)\n",
    "plt.title('CGPA vs. Chance of Admit')\n",
    "plt.xlabel('CGPA')\n",
    "plt.ylabel('Chance of Admit')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(df['University Rating'], df['Chance of Admit '], alpha=0.5)\n",
    "plt.title('University Rating vs. Chance of Admit')\n",
    "plt.xlabel('University Rating')\n",
    "plt.ylabel('Chance of Admit')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of the three selected features vs Chance of Admit\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(df['GRE Score'], df['Chance of Admit '], alpha=0.5)\n",
    "plt.title('GRE Score vs. Chance of Admit')\n",
    "plt.xlabel('GRE Score')\n",
    "plt.ylabel('Chance of Admit')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(df['CGPA'], df['Chance of Admit '], alpha=0.5)\n",
    "plt.title('CGPA vs. Chance of Admit')\n",
    "plt.xlabel('CGPA')\n",
    "plt.ylabel('Chance of Admit')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(df['University Rating'], df['Chance of Admit '], alpha=0.5)\n",
    "plt.title('University Rating vs. Chance of Admit')\n",
    "plt.xlabel('University Rating')\n",
    "plt.ylabel('Chance of Admit')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199574f",
   "metadata": {},
   "source": [
    "<h2>4. Splitting Datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b742d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataet into a training set and testing set\n",
    "X = df[datasets]\n",
    "y = df['Chance of Admit ']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d024843",
   "metadata": {},
   "source": [
    "<h2>5. Linear Regression Model 1: Without PCA </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train original model\n",
    "model_original = LinearRegression()\n",
    "model_original.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred_original = model_original.predict(X_train_scaled)\n",
    "y_test_pred_original = model_original.predict(X_test_scaled)\n",
    "\n",
    "# Calculate MSEs\n",
    "mse_train_original = mean_squared_error(y_train, y_train_pred_original)\n",
    "mse_test_original = mean_squared_error(y_test, y_test_pred_original)\n",
    "\n",
    "print(f'Mean Squared Error (Training) for Original Model: {mse_train_original}')\n",
    "print(f'Mean Squared Error (Testing) for Original Model: {mse_test_original}')\n",
    "\n",
    "# Save predictions\n",
    "original_predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_test_pred_original\n",
    "})\n",
    "original_predictions_df.to_csv('predictions_original.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0dae6e",
   "metadata": {},
   "source": [
    "<h2>6. Linear Regression Model 1: With PCA </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ce58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA to reduce the dimensions to 2 components\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Visualize the PCA-transformed data\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis',edgecolor='k', s=50)\n",
    "plt.title('PCA of Admission Chances (Training Data)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Chance of Admit')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7561ed",
   "metadata": {},
   "source": [
    "<h2>7. Training Linear Regression Models </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad461894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PCA-based model\n",
    "model_pca = LinearRegression()\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred_pca = model_pca.predict(X_train_pca)\n",
    "y_test_pred_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "# Calculate MSEs\n",
    "mse_train_pca = mean_squared_error(y_train, y_train_pred_pca)\n",
    "mse_test_pca = mean_squared_error(y_test, y_test_pred_pca)\n",
    "\n",
    "print(f'Mean Squared Error (Training) for PCA Model: {mse_train_pca}')\n",
    "print(f'Mean Squared Error (Testing) for PCA Model: {mse_test_pca}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d9dbf7",
   "metadata": {},
   "source": [
    "<h2>8. Creating Scatter Plot </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f20977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PCA model predictions\n",
    "pca_predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_test_pred_pca\n",
    "})\n",
    "pca_predictions_df.to_csv('predictions_pca.csv', index=False)\n",
    "\n",
    "# Scatter plot of PCA points in blue and decision boundary in black\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c='blue', edgecolor='k', s=40)\n",
    "\n",
    "# Create a mesh grid to plot decision boundary\n",
    "x_min, x_max = X_test_pca[:, 0].min() - 1, X_test_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_test_pca[:, 1].min() - 1, X_test_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "grid_predictions = model_pca.predict(grid_points)\n",
    "grid_predictions = grid_predictions.reshape(xx.shape)\n",
    "\n",
    "# Draw contour line where prediction = 0.5\n",
    "plt.contour(xx, yy, grid_predictions, levels=[0.5], colors='black')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA Scatter Plot with Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba8ac5",
   "metadata": {},
   "source": [
    "<h2>9. Summary Comparison </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comparison\n",
    "print(\"====== Model Performance Summary ======\")\n",
    "print(f'MSE (Training) Original Model: {mse_train_original}')\n",
    "print(f'MSE (Testing) Original Model: {mse_test_original}')\n",
    "print(f'MSE (Training) PCA Model: {mse_train_pca}')\n",
    "print(f'MSE (Testing) PCA Model: {mse_test_pca}')\n",
    "\n",
    "if mse_test_pca < mse_test_original:\n",
    "    print(\"PCA-based model performed better on test data.\")\n",
    "else:\n",
    "    print(\"Original model performed better on test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d30fe0",
   "metadata": {},
   "source": [
    "<h2>Practice</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200072ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "plt.style.use(['ggplot'])\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the dataset\n",
    "# Note: You'll need to replace 'college_admissions.csv' with your actual file name\n",
    "data = pd.read_csv('college_admissions.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Feature Analysis - Let's examine three key features\n",
    "print(\"\\nAnalyzing key features...\")\n",
    "\n",
    "# Feature 1: GRE Score\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(data['GRE Score'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('GRE Score Distribution')\n",
    "plt.xlabel('GRE Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Feature 2: CGPA\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(data['CGPA'], bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.title('CGPA Distribution')\n",
    "plt.xlabel('CGPA')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Feature 3: University Rating\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(data['University Rating'], bins=5, color='salmon', edgecolor='black')\n",
    "plt.title('University Rating Distribution')\n",
    "plt.xlabel('University Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\nCorrelation with Chance of Admit:\")\n",
    "for column in data.columns:\n",
    "    if column != 'Chance of Admit':\n",
    "        correlation = data[column].corr(data['Chance of Admit '])\n",
    "        print(f\"{column}: {correlation:.4f}\")\n",
    "\n",
    "# Correlation Matrix Visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = data.corr()\n",
    "plt.imshow(correlation_matrix, cmap='coolwarm', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(correlation_matrix)), correlation_matrix.columns, rotation=90)\n",
    "plt.yticks(range(len(correlation_matrix)), correlation_matrix.columns)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter plots of the three selected features vs Chance of Admit\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(data['GRE Score'], data['Chance of Admit '], alpha=0.5)\n",
    "plt.title('GRE Score vs. Chance of Admit')\n",
    "plt.xlabel('GRE Score')\n",
    "plt.ylabel('Chance of Admit')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(data['CGPA'], data['Chance of Admit '], alpha=0.5)\n",
    "plt.title('CGPA vs. Chance of Admit')\n",
    "plt.xlabel('CGPA')\n",
    "plt.ylabel('Chance of Admit')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(data['University Rating'], data['Chance of Admit '], alpha=0.5)\n",
    "plt.title('University Rating vs. Chance of Admit')\n",
    "plt.xlabel('University Rating')\n",
    "plt.ylabel('Chance of Admit')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop('Chance of Admit ', axis=1)\n",
    "y = data['Chance of Admit ']\n",
    "\n",
    "# Split data into training and testing sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Model 1: Linear Regression with all features\n",
    "print(\"\\n--- Model 1: Linear Regression with all features ---\")\n",
    "\n",
    "# Initialize and train the model\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred1 = model1.predict(X_train)\n",
    "y_test_pred1 = model1.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "train_mse1 = mean_squared_error(y_train, y_train_pred1)\n",
    "test_mse1 = mean_squared_error(y_test, y_test_pred1)\n",
    "\n",
    "print(f\"Training MSE: {train_mse1:.6f}\")\n",
    "print(f\"Testing MSE: {test_mse1:.6f}\")\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model1.coef_\n",
    "})\n",
    "print(\"\\nFeature Coefficients:\")\n",
    "print(coefficients.sort_values('Coefficient', ascending=False))\n",
    "\n",
    "# Save predictions to CSV\n",
    "pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_test_pred1\n",
    "}).to_csv('model1_predictions.csv', index=False)\n",
    "\n",
    "# Model 2: Linear Regression with PCA (2 components)\n",
    "print(\"\\n--- Model 2: Linear Regression with PCA (2 components) ---\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Explained variance\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "\n",
    "# Initialize and train the model\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred2 = model2.predict(X_train_pca)\n",
    "y_test_pred2 = model2.predict(X_test_pca)\n",
    "\n",
    "# Calculate MSE\n",
    "train_mse2 = mean_squared_error(y_train, y_train_pred2)\n",
    "test_mse2 = mean_squared_error(y_test, y_test_pred2)\n",
    "\n",
    "print(f\"Training MSE: {train_mse2:.6f}\")\n",
    "print(f\"Testing MSE: {test_mse2:.6f}\")\n",
    "\n",
    "# Save predictions to CSV\n",
    "pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_test_pred2\n",
    "}).to_csv('model2_predictions.csv', index=False)\n",
    "\n",
    "# Visualize PCA results with decision boundary\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create a meshgrid for the decision boundary\n",
    "h = 0.01\n",
    "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict the function values for the whole grid\n",
    "Z = model2.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Create a color plot with the results\n",
    "plt.contour(xx, yy, Z, colors='black', linewidths=0.5)\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis', \n",
    "            edgecolor='k', s=40, alpha=0.7)\n",
    "plt.colorbar(label='Chance of Admit ')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA Results with Decision Boundary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare both models\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "print(f\"Model 1 (All Features) - Training MSE: {train_mse1:.6f}, Testing MSE: {test_mse1:.6f}\")\n",
    "print(f\"Model 2 (PCA) - Training MSE: {train_mse2:.6f}, Testing MSE: {test_mse2:.6f}\")\n",
    "\n",
    "# Calculate improvement or degradation\n",
    "improvement = (test_mse1 - test_mse2) / test_mse1 * 100\n",
    "if improvement > 0:\n",
    "    print(f\"Model 2 improved performance by {improvement:.2f}%\")\n",
    "else:\n",
    "    print(f\"Model 2 degraded performance by {abs(improvement):.2f}%\")\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "if test_mse1 < test_mse2:\n",
    "    print(\"Model 1 (using all features) performed better than the PCA model.\")\n",
    "    print(\"This suggests that all features contribute meaningful information for predicting admission chances.\")\n",
    "else:\n",
    "    print(\"Model 2 (using PCA) performed better than using all features.\")\n",
    "    print(\"This suggests that dimension reduction effectively captured the essential patterns in the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "plt.style.use(['ggplot'])\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the dataset\n",
    "# Note: You'll need to replace 'college_admissions.csv' with your actual file name\n",
    "data = pd.read_csv('college_admissions.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())\n",
    "\n",
    "# We'll focus on only three features as specified: University Rating, CGPA, and GRE Score\n",
    "selected_features = ['University Rating', 'CGPA', 'GRE Score']\n",
    "\n",
    "# Feature Analysis - Examine the three key features\n",
    "print(\"\\nAnalyzing the three selected features...\")\n",
    "\n",
    "# Feature 1: GRE Score\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(data['GRE Score'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('GRE Score Distribution')\n",
    "plt.xlabel('GRE Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Feature 2: CGPA\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(data['CGPA'], bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.title('CGPA Distribution')\n",
    "plt.xlabel('CGPA')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Feature 3: University Rating\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(data['University Rating'], bins=5, color='salmon', edgecolor='black')\n",
    "plt.title('University Rating Distribution')\n",
    "plt.xlabel('University Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis for the three selected features\n",
    "print(\"\\nCorrelation with Chance of Admit:\")\n",
    "for column in selected_features:\n",
    "    correlation = data[column].corr(data['Chance of Admit '])\n",
    "    print(f\"{column}: {correlation:.4f}\")\n",
    "\n",
    "# Scatter plots of the three selected features vs Chance of Admit\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(data['GRE Score'], data['Chance of Admit '], alpha=0.5)\n",
    "plt.title('GRE Score vs. Chance of Admit ')\n",
    "plt.xlabel('GRE Score')\n",
    "plt.ylabel('Chance of Admit ')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(data['CGPA'], data['Chance of Admit '], alpha=0.5)\n",
    "plt.title('CGPA vs. Chance of Admit ')\n",
    "plt.xlabel('CGPA')\n",
    "plt.ylabel('Chance of Admit ')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(data['University Rating'], data['Chance of Admit '], alpha=0.5)\n",
    "plt.title('University Rating vs. Chance of Admit ')\n",
    "plt.xlabel('University Rating')\n",
    "plt.ylabel('Chance of Admit ')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select only the three features we're focusing on\n",
    "X = data[selected_features]\n",
    "y = data['Chance of Admit ']\n",
    "\n",
    "# Split data into training and testing sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Model 1: Linear Regression with the three selected features\n",
    "print(\"\\n--- Model 1: Linear Regression with three selected features ---\")\n",
    "\n",
    "# Initialize and train the model\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred1 = model1.predict(X_train)\n",
    "y_test_pred1 = model1.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "train_mse1 = mean_squared_error(y_train, y_train_pred1)\n",
    "test_mse1 = mean_squared_error(y_test, y_test_pred1)\n",
    "\n",
    "print(f\"Training MSE: {train_mse1:.6f}\")\n",
    "print(f\"Testing MSE: {test_mse1:.6f}\")\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model1.coef_\n",
    "})\n",
    "print(\"\\nFeature Coefficients:\")\n",
    "print(coefficients.sort_values('Coefficient', ascending=False))\n",
    "\n",
    "# Save predictions to CSV\n",
    "pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_test_pred1\n",
    "}).to_csv('model1_predictions.csv', index=False)\n",
    "\n",
    "# Model 2: Linear Regression with PCA (2 components)\n",
    "print(\"\\n--- Model 2: Linear Regression with PCA (2 components) ---\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Explained variance\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "\n",
    "# Component composition\n",
    "print(\"\\nPCA Components Composition:\")\n",
    "component_df = pd.DataFrame(\n",
    "    pca.components_.T, \n",
    "    columns=['PC1', 'PC2'], \n",
    "    index=X.columns\n",
    ")\n",
    "print(component_df)\n",
    "\n",
    "# Initialize and train the model\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred2 = model2.predict(X_train_pca)\n",
    "y_test_pred2 = model2.predict(X_test_pca)\n",
    "\n",
    "# Calculate MSE\n",
    "train_mse2 = mean_squared_error(y_train, y_train_pred2)\n",
    "test_mse2 = mean_squared_error(y_test, y_test_pred2)\n",
    "\n",
    "print(f\"Training MSE: {train_mse2:.6f}\")\n",
    "print(f\"Testing MSE: {test_mse2:.6f}\")\n",
    "\n",
    "# Save predictions to CSV\n",
    "pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_test_pred2\n",
    "}).to_csv('model2_predictions.csv', index=False)\n",
    "\n",
    "# Visualize PCA results with decision boundary\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create a meshgrid for the decision boundary\n",
    "h = 0.01\n",
    "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict the function values for the whole grid\n",
    "Z = model2.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Create a color plot with the results\n",
    "plt.contour(xx, yy, Z, colors='black', linewidths=0.5)\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis', \n",
    "            edgecolor='k', s=40, alpha=0.7)\n",
    "plt.colorbar(label='Chance of Admit')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA Results with Decision Boundary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare both models\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "print(f\"Model 1 (Three Features) - Training MSE: {train_mse1:.6f}, Testing MSE: {test_mse1:.6f}\")\n",
    "print(f\"Model 2 (PCA) - Training MSE: {train_mse2:.6f}, Testing MSE: {test_mse2:.6f}\")\n",
    "\n",
    "# Calculate improvement or degradation\n",
    "improvement = (test_mse1 - test_mse2) / test_mse1 * 100\n",
    "if improvement > 0:\n",
    "    print(f\"Model 2 improved performance by {improvement:.2f}%\")\n",
    "else:\n",
    "    print(f\"Model 2 degraded performance by {abs(improvement):.2f}%\")\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "if test_mse1 < test_mse2:\n",
    "    print(\"Model 1 (using the three features directly) performed better than the PCA model.\")\n",
    "    print(\"This suggests that the raw features provide more predictive power than the PCA components.\")\n",
    "else:\n",
    "    print(\"Model 2 (using PCA) performed better than using the three features directly.\")\n",
    "    print(\"This suggests that dimension reduction effectively captured the essential patterns in the data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
